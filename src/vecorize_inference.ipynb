{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from time import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inference_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # convert from numpy to tensor\n",
    "        x = torch.tensor(self.data[index], dtype=torch.float32)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMENet Deep Neural Network\n",
    "class MIMENetEnsemble(nn.Module):\n",
    "    # Constructor for 5 fully connected layers with bottleneck for layers 4 and 5\n",
    "    # dropout after each layer\n",
    "    def __init__(self, input_size, hidden_size_factor, bottleneck, output_size):\n",
    "        super(MIMENetEnsemble, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size_factor*input_size)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.fc2 = nn.Linear(hidden_size_factor*input_size, hidden_size_factor*input_size)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.fc3 = nn.Linear(hidden_size_factor*input_size, hidden_size_factor*input_size)\n",
    "        self.dropout3 = nn.Dropout(p=0.2)\n",
    "        self.fc4 = nn.Linear(hidden_size_factor*input_size, int(hidden_size_factor*input_size*bottleneck))\n",
    "        self.dropout4 = nn.Dropout(p=0.2)\n",
    "        self.fc5 = nn.Linear(int(hidden_size_factor*input_size*bottleneck), output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.dropout4(x)\n",
    "        x = self.sigmoid(self.fc5(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, x, n, batch_size):\n",
    "    \"\"\"This function is used for inference using the model. It takes in a 2d tensor\n",
    "    and predicts the output using the model. For uncertainty quantification, the\n",
    "    model is run n times and the full distribution is returned.\n",
    "\n",
    "    Args:\n",
    "        x (tensor): Input tensor\n",
    "        n (int): Number of times to run the model\n",
    "    \"\"\"\n",
    "    # set length of input\n",
    "    length = x.shape[0]\n",
    "\n",
    "    # set device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    \n",
    "    # define x as inference dataset\n",
    "    x = inference_dataset(x)\n",
    "\n",
    "    # define dataloader\n",
    "    dataloader = torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # set model\n",
    "    model = model.to(device)\n",
    "\n",
    "    # initialize output\n",
    "    output = np.zeros((length, n))\n",
    "    # run model n times\n",
    "    for i in tqdm(range(n)):\n",
    "        for j, data in enumerate(dataloader):\n",
    "            # only send data to device\n",
    "            data = data.to(device)\n",
    "\n",
    "            # add to output\n",
    "            output[j*batch_size:(j+1)*batch_size, i] = model(data).squeeze().cpu().detach().numpy()\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 35.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.6442608833313\n",
      "(1605, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test predict function\n",
    "model = MIMENetEnsemble(535*4+8, 2, 0.5, 1)\n",
    "batch_size = 2**14\n",
    "# 535*4 by 535*4+8 tensor random input\n",
    "x = np.random.rand(535*3, 535*4+8)\n",
    "\n",
    "start = time()\n",
    "predictions = predict(model, x, 1000, batch_size)\n",
    "end = time()\n",
    "print(end-start)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [01:18<7:17:10, 26.31s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand(\u001b[39m1285605\u001b[39m, \u001b[39m535\u001b[39m\u001b[39m*\u001b[39m\u001b[39m4\u001b[39m\u001b[39m+\u001b[39m\u001b[39m8\u001b[39m)\n\u001b[1;32m      7\u001b[0m start \u001b[39m=\u001b[39m time()\n\u001b[0;32m----> 8\u001b[0m predictions \u001b[39m=\u001b[39m predict(model, x, \u001b[39m1000\u001b[39;49m, batch_size)\n\u001b[1;32m      9\u001b[0m end \u001b[39m=\u001b[39m time()\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(end\u001b[39m-\u001b[39mstart)\n",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(model, x, n, batch_size)\u001b[0m\n\u001b[1;32m     32\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     34\u001b[0m         \u001b[39m# add to output\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m         output[j\u001b[39m*\u001b[39mbatch_size:(j\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mbatch_size, i] \u001b[39m=\u001b[39m model(data)\u001b[39m.\u001b[39;49msqueeze()\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     37\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test predict function\n",
    "model = MIMENetEnsemble(535*4+8, 2, 0.5, 1)\n",
    "batch_size = 2**14\n",
    "# 535*4 by 535*4+8 tensor random input\n",
    "x = np.random.rand(1285605, 535*4+8)\n",
    "\n",
    "start = time()\n",
    "predictions = predict(model, x, 1000, batch_size)\n",
    "end = time()\n",
    "print(end-start)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferSingleKds(model, n_protein_concentrations, n_rounds, path_wildtype, n : int, batch_size : int):\n",
    "\n",
    "    # read in wildtype\n",
    "    with open(path_wildtype, 'r') as f:\n",
    "        wildtype = f.read()\n",
    "\n",
    "    n_features = len(wildtype) * 4 + n_protein_concentrations * n_rounds\n",
    "    \n",
    "    # initialize prediction example (number of nucleotides by number of features)\n",
    "    prediction_example_mutation = np.zeros((len(wildtype)*3, n_features))\n",
    "    prediction_example_wildtype = np.zeros((len(wildtype), n_features))\n",
    "\n",
    "    for pos, feature in enumerate(range(n_protein_concentrations*n_rounds, n_features, 4)):\n",
    "\n",
    "        # get wildtype at position\n",
    "        wildtype_nucleotide = wildtype[pos]\n",
    "\n",
    "        order_nucleotides = ['A', 'C', 'G', 'T']\n",
    "\n",
    "        # get index of wildtype nucleotide\n",
    "        index_wildtype = order_nucleotides.index(wildtype_nucleotide)\n",
    "\n",
    "        # set wildtype nucleotide\n",
    "        prediction_example_wildtype[pos, feature + index_wildtype] = 1\n",
    "\n",
    "        # set mutant nucleotides\n",
    "        indices_mutants = [i for i in range(4) if i != index_wildtype]\n",
    "        prediction_example_mutation[pos*3, feature + indices_mutants[0]] = 1\n",
    "        prediction_example_mutation[pos*3+1, feature + indices_mutants[1]] = 1\n",
    "        prediction_example_mutation[pos*3+2, feature + indices_mutants[2]] = 1\n",
    "\n",
    "\n",
    "        # predict\n",
    "        with torch.no_grad():\n",
    "            wildtype_prediction = predict(model, prediction_example_wildtype, n, batch_size)\n",
    "            mutation_prediction = predict(model, prediction_example_mutation, n, batch_size)\n",
    "\n",
    "            # compute predictions to kds\n",
    "            wildtype_prediction = 1 / wildtype_prediction - 1\n",
    "            mutation_prediction = 1 / mutation_prediction - 1\n",
    "\n",
    "            # repeat every row in wildtype_prediction 3 times\n",
    "            wildtype_prediction = np.repeat(wildtype_prediction, 3, axis=0)\n",
    "\n",
    "            # correct kds\n",
    "            kds_nucleotide = mutation_prediction / wildtype_prediction\n",
    "\n",
    "            # reshape to 3d so that 3 rows are grouped together as one position\n",
    "            kds_position = kds_nucleotide.reshape((len(wildtype), 3, n))\n",
    "\n",
    "            # take max of 3 rows\n",
    "            kds_position = np.max(kds_position, axis=1)\n",
    "\n",
    "\n",
    "    return kds_nucleotide, kds_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 4. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "(1605, 2148)\n",
      "(535, 2148)\n"
     ]
    }
   ],
   "source": [
    "wildtype = \"a\"*535\n",
    "n_features = len(wildtype) * 4 + 4 * 2\n",
    "    \n",
    "# initialize prediction example (number of nucleotides by number of features)\n",
    "prediction_example_mutation = np.zeros((len(wildtype)*3, n_features))\n",
    "prediction_example_wildtype = np.zeros((len(wildtype), n_features))\n",
    "\n",
    "prediction_example_wildtype[0, 0] = 4\n",
    "prediction_example_wildtype[1, 1] = 4\n",
    "print(prediction_example_wildtype[:9, :9])\n",
    "\n",
    "print(prediction_example_mutation.shape)\n",
    "print(prediction_example_wildtype.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(535, 3, 1000)\n",
      "[[[0.79 0.94 0.88 0.38 0.88 0.76 0.34 0.02 0.36 0.83]\n",
      "  [0.75 0.22 0.37 0.75 0.45 0.66 0.64 0.66 0.55 0.22]\n",
      "  [0.7  0.89 0.91 0.67 0.9  0.54 0.59 0.35 0.79 0.19]]\n",
      "\n",
      " [[0.81 0.32 0.61 0.25 0.94 0.95 0.55 0.85 0.3  0.82]\n",
      "  [0.42 0.28 0.6  0.49 0.48 0.6  0.79 0.31 0.23 0.16]\n",
      "  [0.55 0.8  0.65 0.36 0.31 0.08 0.1  0.57 0.38 0.17]]\n",
      "\n",
      " [[0.7  0.21 0.31 0.83 0.68 0.85 0.16 0.54 0.25 0.48]\n",
      "  [0.19 0.02 0.36 0.04 0.75 0.62 0.92 0.75 0.18 0.81]\n",
      "  [0.12 0.93 0.24 0.73 0.42 0.28 0.97 0.83 0.5  0.25]]\n",
      "\n",
      " [[0.63 0.73 0.87 0.27 0.08 0.01 0.34 0.12 0.65 0.45]\n",
      "  [0.59 0.94 0.05 0.2  0.34 0.17 0.97 0.04 0.16 0.74]\n",
      "  [0.41 0.21 0.56 0.59 0.48 0.7  0.38 0.69 0.93 0.8 ]]\n",
      "\n",
      " [[0.82 0.48 0.56 0.79 0.49 0.11 0.58 0.38 0.33 0.38]\n",
      "  [0.53 0.08 0.26 0.52 0.86 0.22 0.2  0.49 0.16 0.22]\n",
      "  [0.67 0.11 0.6  0.49 0.3  0.61 0.53 0.82 0.61 0.9 ]]]\n",
      "(535, 1000)\n",
      "[[0.79 0.94 0.91 0.75 0.9  0.76 0.64 0.66 0.79 0.83]\n",
      " [0.81 0.8  0.65 0.49 0.94 0.95 0.79 0.85 0.38 0.82]\n",
      " [0.7  0.93 0.36 0.83 0.75 0.85 0.97 0.83 0.5  0.81]\n",
      " [0.63 0.94 0.87 0.59 0.48 0.7  0.97 0.69 0.93 0.8 ]\n",
      " [0.82 0.48 0.6  0.79 0.86 0.61 0.58 0.82 0.61 0.9 ]]\n"
     ]
    }
   ],
   "source": [
    "kds_nucleotide = np.random.rand(535*3, 1000)\n",
    "kds_pos = kds_nucleotide.reshape((len(wildtype), 3, 1000)).round(2)\n",
    "print(kds_pos.shape)\n",
    "print(kds_pos[:5, :, :10])\n",
    "kds_pos = np.max(kds_pos, axis=1).round(2)\n",
    "print(kds_pos.shape)\n",
    "print(kds_pos[:5, :10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferPairwiseKds(model, n_protein_concentrations, n_rounds, path_wildtype, n : int):\n",
    "\n",
    "    # read in wildtype\n",
    "    with open(path_wildtype, 'r') as f:\n",
    "        wildtype = f.read()\n",
    "\n",
    "    n_features = len(wildtype) * 4 + n_protein_concentrations * n_rounds\n",
    "    n_pairs_mut = int((len(wildtype)*(len(wildtype)-1)/2)*3*3)\n",
    "    n_pairs_wt = int((len(wildtype)*(len(wildtype)-1)/2))\n",
    "    \n",
    "    # initialize prediction example\n",
    "    prediction_example_mutation = np.zeros((n_pairs_mut, n_features))\n",
    "    prediction_example_wildtype = np.zeros((n_pairs_wt, n_features))\n",
    "\n",
    "    i = 0\n",
    "    for pos1, feature1 in enumerate(range(n_protein_concentrations*n_rounds, n_features, 4)):\n",
    "        for pos2, feature2 in enumerate(range(feature1+4, n_features, 4)):\n",
    "            \n",
    "            # get wildtype at both positions\n",
    "            wildtype1 = wildtype[pos1]\n",
    "            wildtype2 = wildtype[pos2]\n",
    "\n",
    "            order_nucleotides = ['A', 'C', 'G', 'T']\n",
    "\n",
    "            index_wildtype1 = order_nucleotides.index(wildtype1)\n",
    "            index_wildtype2 = order_nucleotides.index(wildtype2)\n",
    "\n",
    "            # set wildtype nucleotides\n",
    "            prediction_example_wildtype[i//9, feature1 + index_wildtype1] = 1\n",
    "            prediction_example_wildtype[i//9, feature2 + index_wildtype2] = 1\n",
    "\n",
    "            # iterate over all possible mutations\n",
    "            for mut1 in range(4):\n",
    "                for mut2 in range(4):\n",
    "\n",
    "                    # skip wildtype\n",
    "                    if mut1 == index_wildtype1 or mut2 == index_wildtype2:\n",
    "                        continue\n",
    "\n",
    "                    # set mutant\n",
    "                    prediction_example_mutation[i, feature1+mut1] = 1\n",
    "                    prediction_example_mutation[i, feature2+mut2] = 1\n",
    "\n",
    "                    i += 1\n",
    "\n",
    "    # predict\n",
    "    with torch.no_grad():\n",
    "\n",
    "        wildtype_prediction = predict(model, prediction_example_wildtype, n, batch_size)\n",
    "        mutation_prediction = predict(model, prediction_example_mutation, n, batch_size)\n",
    "\n",
    "        # compute predictions to kds\n",
    "        wildtype_prediction = 1 / wildtype_prediction - 1\n",
    "        mutation_prediction = 1 / mutation_prediction - 1\n",
    "\n",
    "        # repeat every row in wildtype_prediction 3 times\n",
    "        wildtype_prediction = np.repeat(wildtype_prediction, 9, axis=0)\n",
    "\n",
    "        # correct kds\n",
    "        kds_pairwise = mutation_prediction / wildtype_prediction\n",
    "\n",
    "\n",
    "    return kds_pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1285605\n",
      "2148\n"
     ]
    }
   ],
   "source": [
    "wildtype = \"a\"*535\n",
    "n_features = len(wildtype) * 4 + 4 * 2\n",
    "n_pairs = int((len(wildtype)*(len(wildtype)-1)/2)*3*3)\n",
    "print(n_pairs)\n",
    "print(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142843"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int((len(wildtype)*(len(wildtype)-1)/2)*3*3-10)//9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
