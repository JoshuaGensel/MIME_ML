{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from time import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inference_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # convert from numpy to tensor\n",
    "        x = torch.tensor(self.data[index], dtype=torch.float32)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIMENet Deep Neural Network\n",
    "class MIMENetEnsemble(nn.Module):\n",
    "    # Constructor for 5 fully connected layers with bottleneck for layers 4 and 5\n",
    "    # dropout after each layer\n",
    "    def __init__(self, input_size, hidden_size_factor, bottleneck, output_size):\n",
    "        super(MIMENetEnsemble, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size_factor*input_size)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.fc2 = nn.Linear(hidden_size_factor*input_size, hidden_size_factor*input_size)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.fc3 = nn.Linear(hidden_size_factor*input_size, hidden_size_factor*input_size)\n",
    "        self.dropout3 = nn.Dropout(p=0.2)\n",
    "        self.fc4 = nn.Linear(hidden_size_factor*input_size, int(hidden_size_factor*input_size*bottleneck))\n",
    "        self.dropout4 = nn.Dropout(p=0.2)\n",
    "        self.fc5 = nn.Linear(int(hidden_size_factor*input_size*bottleneck), output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.dropout4(x)\n",
    "        x = self.sigmoid(self.fc5(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, x, n, batch_size):\n",
    "    \"\"\"This function is used for inference using the model. It takes in a 2d tensor\n",
    "    and predicts the output using the model. For uncertainty quantification, the\n",
    "    model is run n times and the full distribution is returned.\n",
    "\n",
    "    Args:\n",
    "        x (tensor): Input tensor\n",
    "        n (int): Number of times to run the model\n",
    "    \"\"\"\n",
    "    # set length of input\n",
    "    length = x.shape[0]\n",
    "\n",
    "    # set device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    \n",
    "    # define x as inference dataset\n",
    "    x = inference_dataset(x)\n",
    "\n",
    "    # define dataloader\n",
    "    dataloader = torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # set model\n",
    "    model = model.to(device)\n",
    "\n",
    "    # initialize output\n",
    "    output = np.zeros((length, n))\n",
    "    # run model n times\n",
    "    for i in tqdm(range(n)):\n",
    "        for j, data in enumerate(dataloader):\n",
    "            # only send data to device\n",
    "            data = data.to(device)\n",
    "\n",
    "            # add to output\n",
    "            output[j*batch_size:(j+1)*batch_size, i] = model(data).squeeze().cpu().detach().numpy()\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:27<00:00, 35.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.6442608833313\n",
      "(1605, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test predict function\n",
    "model = MIMENetEnsemble(535*4+8, 2, 0.5, 1)\n",
    "batch_size = 2**14\n",
    "# 535*4 by 535*4+8 tensor random input\n",
    "x = np.random.rand(535*3, 535*4+8)\n",
    "\n",
    "start = time()\n",
    "predictions = predict(model, x, 1000, batch_size)\n",
    "end = time()\n",
    "print(end-start)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1000 [01:18<7:17:10, 26.31s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand(\u001b[39m1285605\u001b[39m, \u001b[39m535\u001b[39m\u001b[39m*\u001b[39m\u001b[39m4\u001b[39m\u001b[39m+\u001b[39m\u001b[39m8\u001b[39m)\n\u001b[1;32m      7\u001b[0m start \u001b[39m=\u001b[39m time()\n\u001b[0;32m----> 8\u001b[0m predictions \u001b[39m=\u001b[39m predict(model, x, \u001b[39m1000\u001b[39;49m, batch_size)\n\u001b[1;32m      9\u001b[0m end \u001b[39m=\u001b[39m time()\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(end\u001b[39m-\u001b[39mstart)\n",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(model, x, n, batch_size)\u001b[0m\n\u001b[1;32m     32\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     34\u001b[0m         \u001b[39m# add to output\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m         output[j\u001b[39m*\u001b[39mbatch_size:(j\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mbatch_size, i] \u001b[39m=\u001b[39m model(data)\u001b[39m.\u001b[39;49msqueeze()\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     37\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test predict function\n",
    "model = MIMENetEnsemble(535*4+8, 2, 0.5, 1)\n",
    "batch_size = 2**14\n",
    "# 535*4 by 535*4+8 tensor random input\n",
    "x = np.random.rand(1285605, 535*4+8)\n",
    "\n",
    "start = time()\n",
    "predictions = predict(model, x, 1000, batch_size)\n",
    "end = time()\n",
    "print(end-start)\n",
    "print(predictions.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
